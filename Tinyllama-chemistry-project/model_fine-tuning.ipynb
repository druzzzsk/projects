{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Загрузка данных","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"camel-ai/chemistry\")\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T08:45:24.923669Z","iopub.execute_input":"2025-06-22T08:45:24.924280Z","iopub.status.idle":"2025-06-22T09:52:48.525869Z","shell.execute_reply.started":"2025-06-22T08:45:24.924258Z","shell.execute_reply":"2025-06-22T09:52:48.525048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dffd69530984829971fcbc26c037f68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chemistry.zip:   0%|          | 0.00/21.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01e02a250ce4a95b427011f58e31e2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a05e36cc48c49a1bf7fa0996061c264"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['role_1', 'topic;', 'sub_topic', 'message_1', 'message_2'],\n        num_rows: 20000\n    })\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T07:59:32.751480Z","iopub.execute_input":"2025-06-23T07:59:32.751696Z","iopub.status.idle":"2025-06-23T07:59:34.577213Z","shell.execute_reply.started":"2025-06-23T07:59:32.751674Z","shell.execute_reply":"2025-06-23T07:59:34.576468Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:54:21.488010Z","iopub.execute_input":"2025-06-22T09:54:21.488282Z","iopub.status.idle":"2025-06-22T09:54:21.492735Z","shell.execute_reply.started":"2025-06-22T09:54:21.488262Z","shell.execute_reply":"2025-06-22T09:54:21.491894Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['role_1', 'topic;', 'sub_topic', 'message_1', 'message_2'],\n        num_rows: 20000\n    })\n})\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(dataset['train'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:54:37.928295Z","iopub.execute_input":"2025-06-22T09:54:37.928912Z","iopub.status.idle":"2025-06-22T09:54:37.934495Z","shell.execute_reply.started":"2025-06-22T09:54:37.928888Z","shell.execute_reply":"2025-06-22T09:54:37.933766Z"}},"outputs":[{"name":"stdout","text":"{'role_1': 'Chemist_RoleType.ASSISTANT', 'topic;': 'Organic chemistry', 'sub_topic': 'Naming organic compounds', 'message_1': 'What is the IUPAC name for the organic compound with the molecular formula C6H12O2?', 'message_2': 'There can be several isomers with the molecular formula C6H12O2, so it is not possible to provide a specific IUPAC name without more information about the structure of the compound. If you can provide the structure or any additional details, I would be happy to help you determine the IUPAC name.'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Загрузка предобученной модели и токенизатора","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\n# Загружаем токенизатор\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    load_in_8bit=False,\n    load_in_4bit=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Форматирование данных\ndef format_example(example):\n    user_question = example['message_1']\n    assistant_answer = example['message_2']\n\n    prompt = f\"<s>[INST] {user_question} [/INST] {assistant_answer}</s>\"\n    return {\"text\": prompt}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:06:07.338630Z","iopub.execute_input":"2025-06-22T10:06:07.339207Z","iopub.status.idle":"2025-06-22T10:06:07.342897Z","shell.execute_reply.started":"2025-06-22T10:06:07.339184Z","shell.execute_reply":"2025-06-22T10:06:07.342110Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"formatted_dataset = dataset['train'].map(format_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:58:38.707889Z","iopub.execute_input":"2025-06-22T09:58:38.708431Z","iopub.status.idle":"2025-06-22T09:58:40.986262Z","shell.execute_reply.started":"2025-06-22T09:58:38.708410Z","shell.execute_reply":"2025-06-22T09:58:40.985302Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ef65d4ce1943d7ae263f51dca13c8f"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"print(formatted_dataset[0][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:58:46.216929Z","iopub.execute_input":"2025-06-22T09:58:46.217195Z","iopub.status.idle":"2025-06-22T09:58:46.221684Z","shell.execute_reply.started":"2025-06-22T09:58:46.217176Z","shell.execute_reply":"2025-06-22T09:58:46.220985Z"}},"outputs":[{"name":"stdout","text":"<s>[INST] What is the IUPAC name for the organic compound with the molecular formula C6H12O2? [/INST] There can be several isomers with the molecular formula C6H12O2, so it is not possible to provide a specific IUPAC name without more information about the structure of the compound. If you can provide the structure or any additional details, I would be happy to help you determine the IUPAC name.</s>\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Токенизация\ndef tokenize_function(example):\n    tokenized = tokenizer(\n        example[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=384,\n    )\n    # Копируем input_ids как labels\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    return tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:04:51.920502Z","iopub.execute_input":"2025-06-22T10:04:51.920818Z","iopub.status.idle":"2025-06-22T10:04:51.924825Z","shell.execute_reply.started":"2025-06-22T10:04:51.920798Z","shell.execute_reply":"2025-06-22T10:04:51.924074Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=formatted_dataset.column_names\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:04:53.767923Z","iopub.execute_input":"2025-06-22T10:04:53.768555Z","iopub.status.idle":"2025-06-22T10:05:07.069500Z","shell.execute_reply.started":"2025-06-22T10:04:53.768534Z","shell.execute_reply":"2025-06-22T10:05:07.068752Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a66adb084b4474a806e2b417e377972"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Путь для сохранения модели\nmodel_path = \"/kaggle/working/tinyllama-chemistry\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:38:06.789823Z","iopub.execute_input":"2025-06-22T10:38:06.790378Z","iopub.status.idle":"2025-06-22T10:38:06.793818Z","shell.execute_reply.started":"2025-06-22T10:38:06.790357Z","shell.execute_reply":"2025-06-22T10:38:06.793168Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, TaskType\n\n# Настройка LoRa\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,  # мы обучаем генерацию текста\n    inference_mode=False,\n    r=8,             # размер low-rank матриц\n    lora_alpha=16,   # масштаб\n    lora_dropout=0.1 # дропаут во время обучения\n)\n\n# Обернём модель в LoRA\nmodel = get_peft_model(model, peft_config)\n\n# Посмотрим, какие параметры будут обучаться\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:06:20.208833Z","iopub.execute_input":"2025-06-22T10:06:20.209316Z","iopub.status.idle":"2025-06-22T10:06:20.277491Z","shell.execute_reply.started":"2025-06-22T10:06:20.209296Z","shell.execute_reply":"2025-06-22T10:06:20.276866Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n\n# Настройка обучения\ntraining_args = TrainingArguments(\n    output_dir= model_path,   \n    per_device_train_batch_size=2,        \n    gradient_accumulation_steps=8,        \n    num_train_epochs=3,\n    learning_rate=2e-4,\n    logging_steps=20,\n    save_steps=500,\n    save_total_limit=2,\n    fp16=True,                      \n    report_to=\"none\"\n)\n\n# Объединение примеров в батчи\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:39:33.545424Z","iopub.execute_input":"2025-06-22T10:39:33.545744Z","iopub.status.idle":"2025-06-22T10:39:33.576851Z","shell.execute_reply.started":"2025-06-22T10:39:33.545706Z","shell.execute_reply":"2025-06-22T10:39:33.576071Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Запуск дообучения \ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:39:36.492027Z","iopub.execute_input":"2025-06-22T10:39:36.492698Z","iopub.status.idle":"2025-06-22T15:43:44.640035Z","shell.execute_reply.started":"2025-06-22T10:39:36.492673Z","shell.execute_reply":"2025-06-22T15:43:44.639380Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1345370256.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 5:04:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.962600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.939500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.949900</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.945100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.948500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.933500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.931200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.938400</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.930100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.934800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.936200</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.924300</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.933500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.912500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.912600</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.906400</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.918700</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.917400</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.912800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.909600</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.916600</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.903000</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.913700</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.934300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.893000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.885200</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.897900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.902700</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.887300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.905100</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.881000</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.884700</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.888500</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.896500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.888100</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.890600</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.889800</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.883500</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.870100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.892400</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.896200</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.892400</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.887400</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.876500</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.904300</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.869500</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.882300</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.908200</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.864300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.888200</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.874800</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.886000</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.892300</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.863000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.854600</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.877400</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.870400</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.852100</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.877800</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.871100</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.865100</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.867800</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.850800</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.848100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.848800</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.843500</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.873200</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.859900</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.851200</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.850000</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.846900</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.847200</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.851500</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.854000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.855900</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.849200</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.848100</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.849600</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.855600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.830500</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.849600</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.839800</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.867100</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.853100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.847200</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.847800</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.844300</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.841800</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>0.846100</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.855200</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>0.847500</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>0.862700</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>0.841100</td>\n    </tr>\n    <tr>\n      <td>1880</td>\n      <td>0.867700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.839900</td>\n    </tr>\n    <tr>\n      <td>1920</td>\n      <td>0.825700</td>\n    </tr>\n    <tr>\n      <td>1940</td>\n      <td>0.836700</td>\n    </tr>\n    <tr>\n      <td>1960</td>\n      <td>0.845600</td>\n    </tr>\n    <tr>\n      <td>1980</td>\n      <td>0.840500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.844400</td>\n    </tr>\n    <tr>\n      <td>2020</td>\n      <td>0.826900</td>\n    </tr>\n    <tr>\n      <td>2040</td>\n      <td>0.842000</td>\n    </tr>\n    <tr>\n      <td>2060</td>\n      <td>0.846100</td>\n    </tr>\n    <tr>\n      <td>2080</td>\n      <td>0.836100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.843100</td>\n    </tr>\n    <tr>\n      <td>2120</td>\n      <td>0.842100</td>\n    </tr>\n    <tr>\n      <td>2140</td>\n      <td>0.849700</td>\n    </tr>\n    <tr>\n      <td>2160</td>\n      <td>0.853900</td>\n    </tr>\n    <tr>\n      <td>2180</td>\n      <td>0.840900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.846500</td>\n    </tr>\n    <tr>\n      <td>2220</td>\n      <td>0.834800</td>\n    </tr>\n    <tr>\n      <td>2240</td>\n      <td>0.840900</td>\n    </tr>\n    <tr>\n      <td>2260</td>\n      <td>0.834500</td>\n    </tr>\n    <tr>\n      <td>2280</td>\n      <td>0.842100</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.865100</td>\n    </tr>\n    <tr>\n      <td>2320</td>\n      <td>0.834500</td>\n    </tr>\n    <tr>\n      <td>2340</td>\n      <td>0.824400</td>\n    </tr>\n    <tr>\n      <td>2360</td>\n      <td>0.837200</td>\n    </tr>\n    <tr>\n      <td>2380</td>\n      <td>0.847100</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.844100</td>\n    </tr>\n    <tr>\n      <td>2420</td>\n      <td>0.838000</td>\n    </tr>\n    <tr>\n      <td>2440</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>2460</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>2480</td>\n      <td>0.836700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.831700</td>\n    </tr>\n    <tr>\n      <td>2520</td>\n      <td>0.817900</td>\n    </tr>\n    <tr>\n      <td>2540</td>\n      <td>0.815200</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>0.834800</td>\n    </tr>\n    <tr>\n      <td>2580</td>\n      <td>0.826400</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.838500</td>\n    </tr>\n    <tr>\n      <td>2620</td>\n      <td>0.841300</td>\n    </tr>\n    <tr>\n      <td>2640</td>\n      <td>0.837600</td>\n    </tr>\n    <tr>\n      <td>2660</td>\n      <td>0.841900</td>\n    </tr>\n    <tr>\n      <td>2680</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.816100</td>\n    </tr>\n    <tr>\n      <td>2720</td>\n      <td>0.815400</td>\n    </tr>\n    <tr>\n      <td>2740</td>\n      <td>0.850700</td>\n    </tr>\n    <tr>\n      <td>2760</td>\n      <td>0.835000</td>\n    </tr>\n    <tr>\n      <td>2780</td>\n      <td>0.826600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.842600</td>\n    </tr>\n    <tr>\n      <td>2820</td>\n      <td>0.834400</td>\n    </tr>\n    <tr>\n      <td>2840</td>\n      <td>0.817500</td>\n    </tr>\n    <tr>\n      <td>2860</td>\n      <td>0.813800</td>\n    </tr>\n    <tr>\n      <td>2880</td>\n      <td>0.839600</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.818300</td>\n    </tr>\n    <tr>\n      <td>2920</td>\n      <td>0.813100</td>\n    </tr>\n    <tr>\n      <td>2940</td>\n      <td>0.835000</td>\n    </tr>\n    <tr>\n      <td>2960</td>\n      <td>0.818100</td>\n    </tr>\n    <tr>\n      <td>2980</td>\n      <td>0.835700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.819000</td>\n    </tr>\n    <tr>\n      <td>3020</td>\n      <td>0.823700</td>\n    </tr>\n    <tr>\n      <td>3040</td>\n      <td>0.819300</td>\n    </tr>\n    <tr>\n      <td>3060</td>\n      <td>0.844200</td>\n    </tr>\n    <tr>\n      <td>3080</td>\n      <td>0.819900</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.805000</td>\n    </tr>\n    <tr>\n      <td>3120</td>\n      <td>0.821700</td>\n    </tr>\n    <tr>\n      <td>3140</td>\n      <td>0.808800</td>\n    </tr>\n    <tr>\n      <td>3160</td>\n      <td>0.824800</td>\n    </tr>\n    <tr>\n      <td>3180</td>\n      <td>0.830300</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.825900</td>\n    </tr>\n    <tr>\n      <td>3220</td>\n      <td>0.815700</td>\n    </tr>\n    <tr>\n      <td>3240</td>\n      <td>0.833600</td>\n    </tr>\n    <tr>\n      <td>3260</td>\n      <td>0.830600</td>\n    </tr>\n    <tr>\n      <td>3280</td>\n      <td>0.823600</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.814600</td>\n    </tr>\n    <tr>\n      <td>3320</td>\n      <td>0.835000</td>\n    </tr>\n    <tr>\n      <td>3340</td>\n      <td>0.819200</td>\n    </tr>\n    <tr>\n      <td>3360</td>\n      <td>0.834400</td>\n    </tr>\n    <tr>\n      <td>3380</td>\n      <td>0.817000</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.814600</td>\n    </tr>\n    <tr>\n      <td>3420</td>\n      <td>0.830500</td>\n    </tr>\n    <tr>\n      <td>3440</td>\n      <td>0.834700</td>\n    </tr>\n    <tr>\n      <td>3460</td>\n      <td>0.831300</td>\n    </tr>\n    <tr>\n      <td>3480</td>\n      <td>0.823200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.818500</td>\n    </tr>\n    <tr>\n      <td>3520</td>\n      <td>0.814900</td>\n    </tr>\n    <tr>\n      <td>3540</td>\n      <td>0.835100</td>\n    </tr>\n    <tr>\n      <td>3560</td>\n      <td>0.832200</td>\n    </tr>\n    <tr>\n      <td>3580</td>\n      <td>0.815900</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.796600</td>\n    </tr>\n    <tr>\n      <td>3620</td>\n      <td>0.806600</td>\n    </tr>\n    <tr>\n      <td>3640</td>\n      <td>0.812900</td>\n    </tr>\n    <tr>\n      <td>3660</td>\n      <td>0.830400</td>\n    </tr>\n    <tr>\n      <td>3680</td>\n      <td>0.807900</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.808100</td>\n    </tr>\n    <tr>\n      <td>3720</td>\n      <td>0.817000</td>\n    </tr>\n    <tr>\n      <td>3740</td>\n      <td>0.810000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3750, training_loss=0.8563698542277018, metrics={'train_runtime': 18247.5028, 'train_samples_per_second': 3.288, 'train_steps_per_second': 0.206, 'total_flos': 1.4316670550016e+17, 'train_loss': 0.8563698542277018, 'epoch': 3.0})"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"# Проверка модели\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"./tinyllama-mini\", tokenizer=tokenizer)\n\nprompt = \"<s>[INST] What the name of C2H5Cl? [/INST]\"\noutput = pipe(prompt, max_new_tokens=100)\nprint(output[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:34:18.683061Z","iopub.execute_input":"2025-06-22T10:34:18.683802Z","iopub.status.idle":"2025-06-22T10:34:22.083305Z","shell.execute_reply.started":"2025-06-22T10:34:18.683770Z","shell.execute_reply":"2025-06-22T10:34:22.082653Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] What the name of C2H5Cl? [/INST] The name of C2H5Cl is chloroethane.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Сохранение модели\nmodel_path = \"/kaggle/working/tinyllama-chemistry\"\n\nmodel.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('/kaggle/working/tinyllama-chemistry', 'zip', '/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T15:54:01.866309Z","iopub.execute_input":"2025-06-22T15:54:01.867147Z","iopub.status.idle":"2025-06-22T15:54:04.161816Z","shell.execute_reply.started":"2025-06-22T15:54:01.867119Z","shell.execute_reply":"2025-06-22T15:54:04.160982Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/tinyllama-chemistry.zip'"},"metadata":{}}],"execution_count":50}]}
